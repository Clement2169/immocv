{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6963701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import main packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# define variables\n",
    "immo_vis_dir = \"../../data/immo_vis/\"\n",
    "parquet_extension = \".parquet\"\n",
    "metropole_appartement_file = \"ventes-metropole-appartement\" + parquet_extension\n",
    "metropole_maison_file = \"ventes-metropole-maison\" + parquet_extension\n",
    "metropole_appartement_file_cleaned = metropole_appartement_file + \"_step1_clean_\" + parquet_extension\n",
    "\n",
    "dpe_ranking     = ['0','A','B','C','D','E','F','F/G','G','NS','Unknown']\n",
    "dpe_ranking_num = [10,1,2,3,4,5,6,6.5,7,9,10]\n",
    "\n",
    "#  Set plot options\n",
    "LargePlotActive = False\n",
    "MediumPlotActive = False\n",
    "SmallPlotActive = False\n",
    "HeatMapDisplay = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0350b",
   "metadata": {},
   "source": [
    "# # functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7cb43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions  \n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import time\n",
    "\n",
    "def print_numerical_isna(df) :\n",
    "    columns = df.select_dtypes(include='number').columns.tolist()\n",
    "    print (df[columns].isna().sum())\n",
    "\n",
    "def print_categorial_isna(df) :\n",
    "    columns = df.select_dtypes(include='category').columns.tolist()\n",
    "    print (df[columns].isna().sum())     \n",
    "\n",
    "def load_appartement_file (filename) :\n",
    "    start_path = Path(immo_vis_dir)\n",
    "    final_path = start_path / filename\n",
    "    return pd.read_parquet(final_path.as_posix())\n",
    "\n",
    "def save_appartement_file (df, filename) :\n",
    "    start_path = Path(immo_vis_dir)\n",
    "    final_path = start_path / filename\n",
    "    df.to_parquet(path=final_path.as_posix(),index=True)\n",
    "\n",
    "def get_numerical_column_names (df) :\n",
    "    return [ column for column  in df.columns if df[column].dtype not in [\"object\",\"category\"]]\n",
    "\n",
    "def apply_scale_processing(operator,X_train,X_test):\n",
    "    #Operator could be scaler or encode\n",
    "    op=operator\n",
    "    op.fit(X_train)\n",
    "    X_train_treated=pd.DataFrame(op.transform(X_train),columns=X_train.columns)\n",
    "    X_test_treated=pd.DataFrame(op.transform(X_test),columns=X_train.columns)\n",
    "    return X_train_treated,X_test_treated\n",
    "\n",
    "def apply_preprocessing  (df) :\n",
    "    y_tmp =df['prix_bien']\n",
    "    X_tmp =df.drop(columns=['prix_m2_vente','prix_bien','mapCoordonneesLatitude','mapCoordonneesLongitude'])\n",
    "    return X_tmp,y_tmp\n",
    "\n",
    "def create_train_test_data (X ,y,target_size= -1) :\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    #  build the train and test data\n",
    "    X1 = X.iloc[0:target_size]\n",
    "    y1 = y.iloc[0:target_size]\n",
    "    print (X.shape)\n",
    "    return train_test_split(X1,y1,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5beae9",
   "metadata": {},
   "source": [
    "# # decode file and display infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70b8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import appartement file\n",
    "\n",
    "df = load_appartement_file(metropole_appartement_file_cleaned)\n",
    "nb_rows= df.shape[0]\n",
    "nb_cols= df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b283a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ventes-metropole-appartement.parquet_step1_clean_.parquet rows 2077476 columns 45\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2077476 entries, immo-facile-57743459 to 134327817\n",
      "Data columns (total 45 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   etage                      int64  \n",
      " 1   surface                    int64  \n",
      " 2   nb_pieces                  int64  \n",
      " 3   prix_bien                  int64  \n",
      " 4   balcon                     int64  \n",
      " 5   eau                        int64  \n",
      " 6   bain                       int64  \n",
      " 7   mapCoordonneesLatitude     float64\n",
      " 8   mapCoordonneesLongitude    float64\n",
      " 9   annonce_exclusive          int64  \n",
      " 10  nb_etages                  float64\n",
      " 11  places_parking             float64\n",
      " 12  cave                       int64  \n",
      " 13  annee_construction         float64\n",
      " 14  nb_toilettes               int64  \n",
      " 15  nb_terraces                float64\n",
      " 16  videophone                 int64  \n",
      " 17  porte_digicode             int64  \n",
      " 18  ascenseur                  int64  \n",
      " 19  nb_logements_copro         float64\n",
      " 20  charges_copro              float64\n",
      " 21  logement_neuf              float64\n",
      " 22  CODE_IRIS                  int64  \n",
      " 23  DEP                        int64  \n",
      " 24  prix_m2_vente              float64\n",
      " 25  dpeL_num                   int64  \n",
      " 26  ges_class_num              int64  \n",
      " 27  chauf_energy_gaz           int64  \n",
      " 28  chauf_energy_elec          int64  \n",
      " 29  chauf_energy_bois          int64  \n",
      " 30  chauf_energy_fioul         int64  \n",
      " 31  chauf_sys_climatisation    int64  \n",
      " 32  chauf_sys_pompe-chaleur    int64  \n",
      " 33  chauf_sys_convecteur       int64  \n",
      " 34  chauf_sys_radiateur        int64  \n",
      " 35  chauf_sys_chaudiere        int64  \n",
      " 36  chauf_sys_sol              int64  \n",
      " 37  chauf_sys_poele-bois       int64  \n",
      " 38  chauffage_mode_individuel  int64  \n",
      " 39  chauffage_mode_collectif   int64  \n",
      " 40  chauffage_mode_central     int64  \n",
      " 41  expo_has_nord              int64  \n",
      " 42  expo_has_sud               int64  \n",
      " 43  expo_has_est               int64  \n",
      " 44  expo_has_ouest             int64  \n",
      "dtypes: float64(10), int64(35)\n",
      "memory usage: 729.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#  print main infos on appartmeent file\n",
    "\n",
    "print ( f\" {metropole_appartement_file_cleaned} rows {nb_rows} columns {nb_cols}\")\n",
    "print (df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8f453",
   "metadata": {},
   "source": [
    "# 1st Model Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6a7869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "etage                          int64\n",
       "surface                        int64\n",
       "nb_pieces                      int64\n",
       "prix_bien                      int64\n",
       "balcon                         int64\n",
       "eau                            int64\n",
       "bain                           int64\n",
       "mapCoordonneesLatitude       float64\n",
       "mapCoordonneesLongitude      float64\n",
       "annonce_exclusive              int64\n",
       "nb_etages                    float64\n",
       "places_parking               float64\n",
       "cave                           int64\n",
       "annee_construction           float64\n",
       "nb_toilettes                   int64\n",
       "nb_terraces                  float64\n",
       "videophone                     int64\n",
       "porte_digicode                 int64\n",
       "ascenseur                      int64\n",
       "nb_logements_copro           float64\n",
       "charges_copro                float64\n",
       "logement_neuf                float64\n",
       "CODE_IRIS                      int64\n",
       "DEP                            int64\n",
       "prix_m2_vente                float64\n",
       "dpeL_num                       int64\n",
       "ges_class_num                  int64\n",
       "chauf_energy_gaz               int64\n",
       "chauf_energy_elec              int64\n",
       "chauf_energy_bois              int64\n",
       "chauf_energy_fioul             int64\n",
       "chauf_sys_climatisation        int64\n",
       "chauf_sys_pompe-chaleur        int64\n",
       "chauf_sys_convecteur           int64\n",
       "chauf_sys_radiateur            int64\n",
       "chauf_sys_chaudiere            int64\n",
       "chauf_sys_sol                  int64\n",
       "chauf_sys_poele-bois           int64\n",
       "chauffage_mode_individuel      int64\n",
       "chauffage_mode_collectif       int64\n",
       "chauffage_mode_central         int64\n",
       "expo_has_nord                  int64\n",
       "expo_has_sud                   int64\n",
       "expo_has_est                   int64\n",
       "expo_has_ouest                 int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porte_digicode [0 1]\n",
      "ascenceur [0 1]\n",
      "cave [0 1]\n"
     ]
    }
   ],
   "source": [
    "# check dtypes\n",
    "display(df.dtypes)\n",
    "print(\"porte_digicode\",df.porte_digicode.unique())\n",
    "print(\"ascenceur\",df.ascenseur.unique())\n",
    "print(\"cave\",df.ascenseur.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4d7a8",
   "metadata": {},
   "source": [
    "# # Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f91e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['etage', 'surface', 'nb_pieces', 'prix_bien', 'balcon', 'eau', 'bain',\n",
      "       'mapCoordonneesLatitude', 'mapCoordonneesLongitude',\n",
      "       'annonce_exclusive', 'nb_etages', 'places_parking', 'cave',\n",
      "       'annee_construction', 'nb_toilettes', 'nb_terraces', 'videophone',\n",
      "       'porte_digicode', 'ascenseur', 'nb_logements_copro', 'charges_copro',\n",
      "       'logement_neuf', 'CODE_IRIS', 'DEP', 'prix_m2_vente', 'dpeL_num',\n",
      "       'ges_class_num', 'chauf_energy_gaz', 'chauf_energy_elec',\n",
      "       'chauf_energy_bois', 'chauf_energy_fioul', 'chauf_sys_climatisation',\n",
      "       'chauf_sys_pompe-chaleur', 'chauf_sys_convecteur',\n",
      "       'chauf_sys_radiateur', 'chauf_sys_chaudiere', 'chauf_sys_sol',\n",
      "       'chauf_sys_poele-bois', 'chauffage_mode_individuel',\n",
      "       'chauffage_mode_collectif', 'chauffage_mode_central', 'expo_has_nord',\n",
      "       'expo_has_sud', 'expo_has_est', 'expo_has_ouest'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# set target and data\n",
    "print (df.columns)\n",
    "X,y = apply_preprocessing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b90f92",
   "metadata": {},
   "source": [
    "#  # create train test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c6f317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2077476, 41)\n"
     ]
    }
   ],
   "source": [
    "#  train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#  build the train and test data\n",
    "\n",
    "X_train, X_test, y_train, y_test = create_train_test_data(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f8ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply min max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train_scaled,X_test_scaled=apply_scale_processing(MinMaxScaler(),X_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147007b",
   "metadata": {},
   "source": [
    "# # train ans predict models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad021695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_train_models (models,X_train, y_train,X_test,y_test) :\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        print(f\"Entraînement de {name}...\")\n",
    "        \n",
    "        # Mesurer le temps d'entraînement\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        fit_time = time.time() - start_time\n",
    "        \n",
    "        # Mesurer le temps de prédiction\n",
    "        start_time = time.time()\n",
    "        y_pred = model.predict(X_test)\n",
    "        predict_time = time.time() - start_time\n",
    "        \n",
    "        # Calculer les métriques\n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'RMSE': rmse,\n",
    "            'R²': r2,\n",
    "            'Fit_Time': f\"{fit_time:.4f}s\",\n",
    "            'Predict_Time': f\"{predict_time:.4f}s\",\n",
    "            'Total_Time': f\"{fit_time + predict_time:.4f}s\"\n",
    "        })\n",
    "\n",
    "    # Afficher les résultats\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('RMSE')\n",
    "\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe46d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV, LinearRegression, Ridge\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "\n",
    "# Liste des modèles à tester\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'ElasticNet': ElasticNet(alpha=1.0, l1_ratio=0.5),\n",
    "    'ElasticNetCV': ElasticNetCV(),\n",
    "    'LinearSVR': LinearSVR(),\n",
    "    # 'SVR': SVR(),\n",
    "    # 'Random Forest': RandomForestRegressor(n_estimators=20, random_state=42),\n",
    "    'lgb' : lgb.LGBMRegressor(\n",
    "                            objective='regression',\n",
    "                            metric='rmse',\n",
    "                            num_leaves=31,\n",
    "                            learning_rate=0.05,\n",
    "                            force_row_wise=True,\n",
    "                            # feature_fraction=0.9,\n",
    "                        )\n",
    "}\n",
    "\n",
    "# Tester chaque modèle avec mesure du temps\n",
    "results = fit_train_models(models,X_train_scaled,y_train,X_test_scaled,y_test)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df047c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement de XGBRegressor...\n",
      "Entraînement de GradientBoostingRegressor...\n",
      "Entraînement de DecisionTreeRegressor...\n",
      "                       Model           RMSE        R²  Fit_Time Predict_Time  \\\n",
      "0               XGBRegressor  113074.968750  0.837071  29.0264s      0.0698s   \n",
      "2      DecisionTreeRegressor  133045.339455  0.774438   8.4617s      0.0434s   \n",
      "1  GradientBoostingRegressor  187627.051602  0.551402  58.8978s      0.1848s   \n",
      "\n",
      "  Total_Time  \n",
      "0   29.0963s  \n",
      "2    8.5051s  \n",
      "1   59.0826s  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Liste des modèles à tester\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "models = {\n",
    "    # 'KNeighborsRegressor': KNeighborsRegressor(n_neighbors=5),\n",
    "    'XGBRegressor' : XGBRegressor(n_estimators=100, random_state=42),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    # 'GradientBoostingRegressor': GradientBoostingRegressor(n_estimators=20, random_state=42),\n",
    "    # 'MLPRegressor': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),\n",
    "}\n",
    "\n",
    "# Tester chaque modèle avec mesure du temps\n",
    "\n",
    "results = fit_train_models(models,X_train_scaled,y_train,X_test_scaled,y_test)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6bf76",
   "metadata": {},
   "source": [
    "#  # improve hyper parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98730a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X1,y1 = apply_preprocessing(df)\n",
    "X_train1, X_test1, y_train1,y_test1 = create_train_test_data(X1,y1,2000)\n",
    "X_train_scaled1,X_test_scaled1 = apply_scale_processing(MinMaxScaler(),X_train1,X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d70c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import  mean_absolute_error, mean_squared_error\n",
    "\n",
    "def optimize_hyperparameters_grid_search (estimator_name, estimator, param_grid,X_train, y_train,X_test,y_test) :\n",
    "# Initialize XGBRegressor\n",
    "\n",
    "    # Setup GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,  # 5-fold cross-validation\n",
    "        scoring='neg_mean_squared_error',  # or 'r2', 'neg_mean_absolute_error'\n",
    "        verbose=2,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True\n",
    "    )\n",
    "\n",
    "    # Fit the grid search\n",
    "    print(f\"Starting GridSearchCV {estimator_name} fit ...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Ending GridSearchCV {estimator_name} fit ...\")\n",
    "\n",
    "    # Best parameters and score\n",
    "    print(f\"Best estimator : {estimator_name} {grid_search.best_estimator_}\")\n",
    "    print(f\"Best paramters : {estimator_name} {grid_search.best_params_}\")\n",
    "    print(f\"Best score : {estimator_name} {grid_search.best_params_}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST PARAMETERS:\")\n",
    "    print(\"=\"*60)\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"{param:20s}: {value}\")\n",
    "\n",
    "    print(f\"\\nBest CV Score (neg MSE): {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Best CV RMSE: {np.sqrt(-grid_search.best_score_):.4f}\")\n",
    "\n",
    "    # Train best model on full training set and evaluate\n",
    "    print(f\"Starting GridSearchCV {estimator_name} predict ...\")\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST SET PERFORMANCE:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"MSE:  {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE:  {mae:.4f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    # Display top 10 parameter combinations\n",
    "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "    results_df['mean_rmse'] = np.sqrt(-results_df['mean_test_score'])\n",
    "    top_10 = results_df.nsmallest(10, 'mean_rmse')[['params', 'mean_rmse', 'std_test_score']]\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TOP 10 PARAMETER COMBINATIONS:\")\n",
    "    print(\"=\"*60)\n",
    "    print(top_10.to_string(index=False))\n",
    "\n",
    "    # Feature importance plot\n",
    "    feature_importance = best_model.feature_importances_\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(feature_importance)), feature_importance)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Index')\n",
    "    plt.title('Feature Importance from Best XGBRegressor Model')\n",
    "    plt.tight_layout()\n",
    "   \n",
    "\n",
    "    # Save the best model\n",
    "    # import joblib\n",
    "    # joblib.dump(best_model, 'best_xgb_model.pkl')\n",
    "    # print(\"Best model saved as 'best_xgb_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66e279f",
   "metadata": {},
   "source": [
    "#  # hyper parameters XgbRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ad955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200,300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "param_grid1 = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'gamma': [0, 0.1, 0.3],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'reg_lambda': [0.1, 1.0, 10.0],\n",
    "    'reg_alpha': [0, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize XGBRegressor\n",
    "xgb = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "optimize_hyperparameters_grid_search(\"XGBRegressor\", xgb,param_grid1,X_train_scaled1, y_train1,X_test_scaled1,y_test1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac975039",
   "metadata": {},
   "source": [
    "#  # hyper parameters DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'criterion': ['squared_error', 'friedman_mse', 'absolute_error']\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "optimize_hyperparameters_grid_search(\"DecisionTreeRegressor\", dt,param_grid,X_train_scaled1, y_train1,X_test_scaled1,y_test1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "immocv-Hc0iPIjN-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
