{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b05503",
   "metadata": {},
   "source": [
    "Exploration des données CSV téléchargées de https://www.data.gouv.fr/datasets/demandes-de-valeurs-foncieres-geolocalisees/ \n",
    "\n",
    "Voir le document ./dvf.csv/README-CSV.md pour plus d'information sur le dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d5f23-6393-4481-921e-33e5ee89d08a",
   "metadata": {},
   "source": [
    "# Read CSV chunk and only keep house sells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "904d9c6a-61ba-449f-a3b6-2e062d0e0a63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement chunk 1...\n",
      "Traitement chunk 2...\n",
      "Traitement chunk 3...\n",
      "Traitement chunk 4...\n",
      "Traitement chunk 5...\n",
      "Traitement chunk 6...\n",
      "Traitement chunk 7...\n",
      "Traitement chunk 8...\n",
      "Traitement chunk 9...\n",
      "Traitement chunk 10...\n",
      "Traitement chunk 11...\n",
      "Traitement chunk 12...\n",
      "Traitement chunk 13...\n",
      "Traitement chunk 14...\n",
      "Traitement chunk 15...\n",
      "Traitement chunk 16...\n",
      "Traitement chunk 17...\n",
      "Traitement chunk 18...\n",
      "Traitement chunk 19...\n",
      "Traitement chunk 20...\n",
      "Traitement chunk 21...\n",
      "Traitement chunk 22...\n",
      "Traitement chunk 23...\n",
      "Traitement chunk 24...\n",
      "Traitement chunk 25...\n",
      "Traitement chunk 26...\n",
      "Traitement chunk 27...\n",
      "Traitement chunk 28...\n",
      "Traitement chunk 29...\n",
      "Traitement chunk 30...\n",
      "Traitement chunk 31...\n",
      "Traitement chunk 32...\n",
      "Traitement chunk 33...\n",
      "Traitement chunk 34...\n",
      "Traitement chunk 35...\n",
      "Traitement chunk 36...\n",
      "Traitement chunk 37...\n",
      "Traitement chunk 38...\n",
      "Traitement chunk 39...\n",
      "Traitement chunk 40...\n",
      "Traitement chunk 41...\n",
      "Traitement chunk 42...\n",
      "Traitement chunk 43...\n",
      "Traitement chunk 44...\n",
      "Traitement chunk 45...\n",
      "Traitement chunk 46...\n",
      "Traitement chunk 47...\n",
      "Traitement chunk 48...\n",
      "Traitement chunk 49...\n",
      "Traitement chunk 50...\n",
      "Traitement chunk 51...\n",
      "Traitement chunk 52...\n",
      "Traitement chunk 53...\n",
      "Traitement chunk 54...\n",
      "Traitement chunk 55...\n",
      "Traitement chunk 56...\n",
      "Traitement chunk 57...\n",
      "Traitement chunk 58...\n",
      "Traitement chunk 59...\n",
      "Traitement chunk 60...\n",
      "Traitement chunk 61...\n",
      "Traitement chunk 62...\n",
      "Traitement chunk 63...\n",
      "Traitement chunk 64...\n",
      "Traitement chunk 65...\n",
      "Traitement chunk 66...\n",
      "Traitement chunk 67...\n",
      "Traitement chunk 68...\n",
      "Traitement chunk 69...\n",
      "Traitement chunk 70...\n",
      "Traitement chunk 71...\n",
      "Traitement chunk 72...\n",
      "Traitement chunk 73...\n",
      "Traitement chunk 74...\n",
      "Traitement chunk 75...\n",
      "Traitement chunk 76...\n",
      "Traitement chunk 77...\n",
      "Traitement chunk 78...\n",
      "Traitement chunk 79...\n",
      "Traitement chunk 80...\n",
      "Traitement chunk 81...\n",
      "Traitement chunk 82...\n",
      "Traitement chunk 83...\n",
      "Traitement chunk 84...\n",
      "Traitement chunk 85...\n",
      "Traitement chunk 86...\n",
      "Traitement chunk 87...\n",
      "Traitement chunk 88...\n",
      "Traitement chunk 89...\n",
      "Traitement chunk 90...\n",
      "Traitement chunk 91...\n",
      "Traitement chunk 92...\n",
      "Traitement chunk 93...\n",
      "Traitement chunk 94...\n",
      "Traitement chunk 95...\n",
      "Traitement chunk 96...\n",
      "Traitement chunk 97...\n",
      "Traitement chunk 98...\n",
      "Traitement chunk 99...\n",
      "Traitement chunk 100...\n",
      "Traitement chunk 101...\n",
      "Traitement chunk 102...\n",
      "Traitement chunk 103...\n",
      "Traitement chunk 104...\n",
      "Traitement chunk 105...\n",
      "Traitement chunk 106...\n",
      "Traitement chunk 107...\n",
      "Traitement chunk 108...\n",
      "Traitement chunk 109...\n",
      "Traitement chunk 110...\n",
      "Traitement chunk 111...\n",
      "Traitement chunk 112...\n",
      "Traitement chunk 113...\n",
      "Traitement chunk 114...\n",
      "Traitement chunk 115...\n",
      "Traitement chunk 116...\n",
      "Traitement chunk 117...\n",
      "Traitement chunk 118...\n",
      "Traitement chunk 119...\n",
      "Traitement chunk 120...\n",
      "Traitement chunk 121...\n",
      "Traitement chunk 122...\n",
      "Traitement chunk 123...\n",
      "Traitement chunk 124...\n",
      "Traitement chunk 125...\n",
      "Traitement chunk 126...\n",
      "Traitement chunk 127...\n",
      "Traitement chunk 128...\n",
      "Traitement chunk 129...\n",
      "Traitement chunk 130...\n",
      "Traitement chunk 131...\n",
      "Traitement chunk 132...\n",
      "Traitement chunk 133...\n",
      "Traitement chunk 134...\n",
      "Traitement chunk 135...\n",
      "Traitement chunk 136...\n",
      "Traitement chunk 137...\n",
      "Traitement chunk 138...\n",
      "Traitement chunk 139...\n",
      "Traitement chunk 140...\n",
      "Traitement chunk 141...\n",
      "Traitement chunk 142...\n",
      "Traitement chunk 143...\n",
      "Traitement chunk 144...\n",
      "Traitement chunk 145...\n",
      "Traitement chunk 146...\n",
      "Traitement chunk 147...\n",
      "Traitement chunk 148...\n",
      "Traitement chunk 149...\n",
      "Traitement chunk 150...\n",
      "Traitement chunk 151...\n",
      "Traitement chunk 152...\n",
      "Traitement chunk 153...\n",
      "Traitement chunk 154...\n",
      "Traitement chunk 155...\n",
      "Traitement chunk 156...\n",
      "Traitement chunk 157...\n",
      "Traitement chunk 158...\n",
      "Traitement chunk 159...\n",
      "Traitement chunk 160...\n",
      "Traitement chunk 161...\n",
      "Traitement chunk 162...\n",
      "Traitement chunk 163...\n",
      "Traitement chunk 164...\n",
      "Traitement chunk 165...\n",
      "Traitement chunk 166...\n",
      "Traitement chunk 167...\n",
      "Traitement chunk 168...\n",
      "Traitement chunk 169...\n",
      "Traitement chunk 170...\n",
      "Traitement chunk 171...\n",
      "Traitement chunk 172...\n",
      "Traitement chunk 173...\n",
      "Traitement chunk 174...\n",
      "Traitement chunk 175...\n",
      "Traitement chunk 176...\n",
      "Traitement chunk 177...\n",
      "Traitement chunk 178...\n",
      "Traitement chunk 179...\n",
      "Traitement chunk 180...\n",
      "Traitement chunk 181...\n",
      "Traitement chunk 182...\n",
      "Traitement chunk 183...\n",
      "Traitement chunk 184...\n",
      "Traitement chunk 185...\n",
      "Traitement chunk 186...\n",
      "Traitement chunk 187...\n",
      "Traitement chunk 188...\n",
      "Traitement chunk 189...\n",
      "Traitement chunk 190...\n",
      "Traitement chunk 191...\n",
      "Traitement chunk 192...\n",
      "Traitement chunk 193...\n",
      "Traitement chunk 194...\n",
      "Traitement chunk 195...\n",
      "Traitement chunk 196...\n",
      "Traitement chunk 197...\n",
      "Traitement chunk 198...\n",
      "Traitement chunk 199...\n",
      "Traitement chunk 200...\n",
      "Traitement chunk 201...\n",
      "Traitement chunk 202...\n",
      "le processus a pris : 2.311095110575358 minute\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "a=time.time()\n",
    "\n",
    "chunks = []\n",
    "chunk_size = 100000\n",
    "fichier = './dvf.csv/dvf.csv'\n",
    "\n",
    "\n",
    "def conditions(chunk):\n",
    "    return chunk['nature_mutation'].isin(['Vente', \"Vente en l'état futur d'achèvement\"]) & chunk['code_type_local'].isin([1,3])\n",
    "\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(fichier, sep=',', chunksize=chunk_size, low_memory=False,\n",
    "                                      usecols = ['id_mutation','date_mutation','numero_disposition','nature_mutation','valeur_fonciere',\n",
    "                                  'adresse_numero','adresse_suffixe','adresse_nom_voie','adresse_code_voie',\n",
    "                                  'code_postal','code_commune','code_departement','numero_volume',\n",
    "                                  'lot1_numero','lot1_surface_carrez','lot2_numero','lot2_surface_carrez','lot3_numero',\n",
    "                                  'lot3_surface_carrez','lot4_numero','lot4_surface_carrez','lot5_numero','lot5_surface_carrez','nombre_lots',\n",
    "                                  'code_type_local','type_local',\n",
    "                                  'surface_terrain','surface_reelle_bati','nombre_pieces_principales',\n",
    "                                  'code_nature_culture','nature_culture','code_nature_culture_speciale','nature_culture_speciale',\n",
    "                                  'longitude','latitude'],\n",
    "                                     dtype = {\n",
    "                                   'numero_disposition':'Int64',\n",
    "                                   'valeur_fonciere' : 'Float64',\n",
    "                                   'adresse_numero':'Int64','adresse_suffixe': 'string', 'code_postal': 'Int64','adresse_code_voie': 'string',\n",
    "                                   'code_commune': 'string', 'code_departement': 'string', \n",
    "                                   'numero_volume': 'string',\n",
    "                                   'lot1_numero': 'string','lot1_surface_carrez':'Float64',\n",
    "                                   'lot2_numero': 'string','lot2_surface_carrez':'Float64',\n",
    "                                   'lot3_numero': 'string','lot3_surface_carrez':'Float64',\n",
    "                                   'lot4_numero': 'string','lot4_surface_carrez':'Float64',\n",
    "                                   'lot5_numero': 'string','lot5_surface_carrez':'Float64',\n",
    "                                   'nombre_lots':'Int64','code_type_local':'Int64','type_local': 'string',\n",
    "                                   'surface_terrain':'float','surface_reelle_bati' : 'float','nombre_pieces_principales' : 'Int64',\n",
    "                                   'nature_culture_speciale': 'string','code_nature_culture_speciale': 'string',\n",
    "                                   'longitude':'Float64','latitude':'Float64'\n",
    "                                } \n",
    "                                     )):\n",
    "    print(f\"Traitement chunk {i+1}...\")\n",
    "    chunks.append(chunk[conditions(chunk)])\n",
    "    \n",
    "df=pd.concat(chunks, ignore_index=True)    \n",
    "print (f'le processus a pris : {(time.time()-a)/60} minute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b27aa-ddc8-48c6-8cdc-fc0edd8b16a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(len(chunks)):\n",
    "    try : \n",
    "        df=pd.concat([chunks.pop(),df], ignore_index=True)\n",
    "    except:\n",
    "        df.to_parquet(f'./dvf_temp_{str(i)}.parquet')\n",
    "        df=pd.DataFrame()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "678141d1-5bcc-486e-a3fa-178a2f72974e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_parquet('dvf_vente_maison.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14441443-2a13-4fa8-bc4a-edda37617e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lot1_surface_carrez</th>\n",
       "      <th>lot2_surface_carrez</th>\n",
       "      <th>lot3_surface_carrez</th>\n",
       "      <th>lot4_surface_carrez</th>\n",
       "      <th>lot5_surface_carrez</th>\n",
       "      <th>surface_reelle_bati</th>\n",
       "      <th>surface_terrain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8201651</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8201652</th>\n",
       "      <td>125.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lot1_surface_carrez  lot2_surface_carrez  lot3_surface_carrez  \\\n",
       "8201651                 <NA>                 <NA>                 <NA>   \n",
       "8201652                125.0                 <NA>                 <NA>   \n",
       "\n",
       "         lot4_surface_carrez  lot5_surface_carrez  surface_reelle_bati  \\\n",
       "8201651                 <NA>                 <NA>                  NaN   \n",
       "8201652                 <NA>                 <NA>                  NaN   \n",
       "\n",
       "         surface_terrain  \n",
       "8201651              NaN  \n",
       "8201652              NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['id_mutation']=='2024-1217784'].filter(like='surface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f58c75-dab3-4825-a74e-6eb30baa4a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f649de4-67af-40d5-917e-135a22b252cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3419470"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['code_type_local']==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074c5968-664a-4c6b-8b6d-0d91457aed80",
   "metadata": {},
   "source": [
    "# Read CSV chunk and only keep appartement sells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f1148e-dcbf-48f7-b7fd-0df51d7683e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement chunk 1...\n",
      "Traitement chunk 2...\n",
      "Traitement chunk 3...\n",
      "Traitement chunk 4...\n",
      "Traitement chunk 5...\n",
      "Traitement chunk 6...\n",
      "Traitement chunk 7...\n",
      "Traitement chunk 8...\n",
      "Traitement chunk 9...\n",
      "Traitement chunk 10...\n",
      "Traitement chunk 11...\n",
      "Traitement chunk 12...\n",
      "Traitement chunk 13...\n",
      "Traitement chunk 14...\n",
      "Traitement chunk 15...\n",
      "Traitement chunk 16...\n",
      "Traitement chunk 17...\n",
      "Traitement chunk 18...\n",
      "Traitement chunk 19...\n",
      "Traitement chunk 20...\n",
      "Traitement chunk 21...\n",
      "Traitement chunk 22...\n",
      "Traitement chunk 23...\n",
      "Traitement chunk 24...\n",
      "Traitement chunk 25...\n",
      "Traitement chunk 26...\n",
      "Traitement chunk 27...\n",
      "Traitement chunk 28...\n",
      "Traitement chunk 29...\n",
      "Traitement chunk 30...\n",
      "Traitement chunk 31...\n",
      "Traitement chunk 32...\n",
      "Traitement chunk 33...\n",
      "Traitement chunk 34...\n",
      "Traitement chunk 35...\n",
      "Traitement chunk 36...\n",
      "Traitement chunk 37...\n",
      "Traitement chunk 38...\n",
      "Traitement chunk 39...\n",
      "Traitement chunk 40...\n",
      "Traitement chunk 41...\n",
      "Traitement chunk 42...\n",
      "Traitement chunk 43...\n",
      "Traitement chunk 44...\n",
      "Traitement chunk 45...\n",
      "Traitement chunk 46...\n",
      "Traitement chunk 47...\n",
      "Traitement chunk 48...\n",
      "Traitement chunk 49...\n",
      "Traitement chunk 50...\n",
      "Traitement chunk 51...\n",
      "Traitement chunk 52...\n",
      "Traitement chunk 53...\n",
      "Traitement chunk 54...\n",
      "Traitement chunk 55...\n",
      "Traitement chunk 56...\n",
      "Traitement chunk 57...\n",
      "Traitement chunk 58...\n",
      "Traitement chunk 59...\n",
      "Traitement chunk 60...\n",
      "Traitement chunk 61...\n",
      "Traitement chunk 62...\n",
      "Traitement chunk 63...\n",
      "Traitement chunk 64...\n",
      "Traitement chunk 65...\n",
      "Traitement chunk 66...\n",
      "Traitement chunk 67...\n",
      "Traitement chunk 68...\n",
      "Traitement chunk 69...\n",
      "Traitement chunk 70...\n",
      "Traitement chunk 71...\n",
      "Traitement chunk 72...\n",
      "Traitement chunk 73...\n",
      "Traitement chunk 74...\n",
      "Traitement chunk 75...\n",
      "Traitement chunk 76...\n",
      "Traitement chunk 77...\n",
      "Traitement chunk 78...\n",
      "Traitement chunk 79...\n",
      "Traitement chunk 80...\n",
      "Traitement chunk 81...\n",
      "Traitement chunk 82...\n",
      "Traitement chunk 83...\n",
      "Traitement chunk 84...\n",
      "Traitement chunk 85...\n",
      "Traitement chunk 86...\n",
      "Traitement chunk 87...\n",
      "Traitement chunk 88...\n",
      "Traitement chunk 89...\n",
      "Traitement chunk 90...\n",
      "Traitement chunk 91...\n",
      "Traitement chunk 92...\n",
      "Traitement chunk 93...\n",
      "Traitement chunk 94...\n",
      "Traitement chunk 95...\n",
      "Traitement chunk 96...\n",
      "Traitement chunk 97...\n",
      "Traitement chunk 98...\n",
      "Traitement chunk 99...\n",
      "Traitement chunk 100...\n",
      "Traitement chunk 101...\n",
      "Traitement chunk 102...\n",
      "Traitement chunk 103...\n",
      "Traitement chunk 104...\n",
      "Traitement chunk 105...\n",
      "Traitement chunk 106...\n",
      "Traitement chunk 107...\n",
      "Traitement chunk 108...\n",
      "Traitement chunk 109...\n",
      "Traitement chunk 110...\n",
      "Traitement chunk 111...\n",
      "Traitement chunk 112...\n",
      "Traitement chunk 113...\n",
      "Traitement chunk 114...\n",
      "Traitement chunk 115...\n",
      "Traitement chunk 116...\n",
      "Traitement chunk 117...\n",
      "Traitement chunk 118...\n",
      "Traitement chunk 119...\n",
      "Traitement chunk 120...\n",
      "Traitement chunk 121...\n",
      "Traitement chunk 122...\n",
      "Traitement chunk 123...\n",
      "Traitement chunk 124...\n",
      "Traitement chunk 125...\n",
      "Traitement chunk 126...\n",
      "Traitement chunk 127...\n",
      "Traitement chunk 128...\n",
      "Traitement chunk 129...\n",
      "Traitement chunk 130...\n",
      "Traitement chunk 131...\n",
      "Traitement chunk 132...\n",
      "Traitement chunk 133...\n",
      "Traitement chunk 134...\n",
      "Traitement chunk 135...\n",
      "Traitement chunk 136...\n",
      "Traitement chunk 137...\n",
      "Traitement chunk 138...\n",
      "Traitement chunk 139...\n",
      "Traitement chunk 140...\n",
      "Traitement chunk 141...\n",
      "Traitement chunk 142...\n",
      "Traitement chunk 143...\n",
      "Traitement chunk 144...\n",
      "Traitement chunk 145...\n",
      "Traitement chunk 146...\n",
      "Traitement chunk 147...\n",
      "Traitement chunk 148...\n",
      "Traitement chunk 149...\n",
      "Traitement chunk 150...\n",
      "Traitement chunk 151...\n",
      "Traitement chunk 152...\n",
      "Traitement chunk 153...\n",
      "Traitement chunk 154...\n",
      "Traitement chunk 155...\n",
      "Traitement chunk 156...\n",
      "Traitement chunk 157...\n",
      "Traitement chunk 158...\n",
      "Traitement chunk 159...\n",
      "Traitement chunk 160...\n",
      "Traitement chunk 161...\n",
      "Traitement chunk 162...\n",
      "Traitement chunk 163...\n",
      "Traitement chunk 164...\n",
      "Traitement chunk 165...\n",
      "Traitement chunk 166...\n",
      "Traitement chunk 167...\n",
      "Traitement chunk 168...\n",
      "Traitement chunk 169...\n",
      "Traitement chunk 170...\n",
      "Traitement chunk 171...\n",
      "Traitement chunk 172...\n",
      "Traitement chunk 173...\n",
      "Traitement chunk 174...\n",
      "Traitement chunk 175...\n",
      "Traitement chunk 176...\n",
      "Traitement chunk 177...\n",
      "Traitement chunk 178...\n",
      "Traitement chunk 179...\n",
      "Traitement chunk 180...\n",
      "Traitement chunk 181...\n",
      "Traitement chunk 182...\n",
      "Traitement chunk 183...\n",
      "Traitement chunk 184...\n",
      "Traitement chunk 185...\n",
      "Traitement chunk 186...\n",
      "Traitement chunk 187...\n",
      "Traitement chunk 188...\n",
      "Traitement chunk 189...\n",
      "Traitement chunk 190...\n",
      "Traitement chunk 191...\n",
      "Traitement chunk 192...\n",
      "Traitement chunk 193...\n",
      "Traitement chunk 194...\n",
      "Traitement chunk 195...\n",
      "Traitement chunk 196...\n",
      "Traitement chunk 197...\n",
      "Traitement chunk 198...\n",
      "Traitement chunk 199...\n",
      "Traitement chunk 200...\n",
      "Traitement chunk 201...\n",
      "Traitement chunk 202...\n",
      "le processus a pris : 3.516196978092194 minute\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "a=time.time()\n",
    "\n",
    "chunks = []\n",
    "chunk_size = 100000\n",
    "fichier = './dvf.csv/dvf.csv'\n",
    "\n",
    "\n",
    "def conditions(chunk):\n",
    "    return chunk['nature_mutation'].isin(['Vente', \"Vente en l'état futur d'achèvement\"]) & chunk['code_type_local'].isin([2])\n",
    "\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(fichier, sep=',', chunksize=chunk_size, low_memory=False,\n",
    "                                      usecols = ['id_mutation','date_mutation','numero_disposition','nature_mutation','valeur_fonciere',\n",
    "                                  'adresse_numero','adresse_suffixe','adresse_nom_voie','adresse_code_voie',\n",
    "                                  'code_postal','code_commune','code_departement','numero_volume',\n",
    "                                  'lot1_numero','lot1_surface_carrez','lot2_numero','lot2_surface_carrez','lot3_numero',\n",
    "                                  'lot3_surface_carrez','lot4_numero','lot4_surface_carrez','lot5_numero','lot5_surface_carrez','nombre_lots',\n",
    "                                  'code_type_local','type_local',\n",
    "                                  'surface_terrain','surface_reelle_bati','nombre_pieces_principales',\n",
    "                                  'code_nature_culture','nature_culture','code_nature_culture_speciale','nature_culture_speciale',\n",
    "                                  'longitude','latitude'],\n",
    "                                     dtype = {\n",
    "                                   'numero_disposition':'Int64',\n",
    "                                   'valeur_fonciere' : 'Float64',\n",
    "                                   'adresse_numero':'Int64','adresse_suffixe': 'string', 'code_postal': 'Int64','adresse_code_voie': 'string',\n",
    "                                   'code_commune': 'string', 'code_departement': 'string', \n",
    "                                   'numero_volume': 'string',\n",
    "                                   'lot1_numero': 'string','lot1_surface_carrez':'Float64',\n",
    "                                   'lot2_numero': 'string','lot2_surface_carrez':'Float64',\n",
    "                                   'lot3_numero': 'string','lot3_surface_carrez':'Float64',\n",
    "                                   'lot4_numero': 'string','lot4_surface_carrez':'Float64',\n",
    "                                   'lot5_numero': 'string','lot5_surface_carrez':'Float64',\n",
    "                                   'nombre_lots':'Int64','code_type_local':'Int64','type_local': 'string',\n",
    "                                   'surface_terrain':'float','surface_reelle_bati' : 'float','nombre_pieces_principales' : 'Int64',\n",
    "                                   'nature_culture_speciale': 'string','code_nature_culture_speciale': 'string',\n",
    "                                   'longitude':'Float64','latitude':'Float64'\n",
    "                                } \n",
    "                                     )):\n",
    "    print(f\"Traitement chunk {i+1}...\")\n",
    "    chunks.append(chunk[conditions(chunk)])\n",
    "    \n",
    "df_appart=pd.concat(chunks, ignore_index=True)    \n",
    "print (f'le processus a pris : {(time.time()-a)/60} minute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86996d32-06b8-4cb1-9d7f-fd9c03a96dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(len(chunks)):\n",
    "    try : \n",
    "        df=pd.concat([chunks.pop(),df], ignore_index=True)\n",
    "    except:\n",
    "        df.to_parquet(f'./dvf_temp_{str(i)}.parquet')\n",
    "        df=pd.DataFrame()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "448aacee-3580-4763-83c4-5a9175c10df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2908327 entries, 0 to 2908326\n",
      "Data columns (total 35 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0   id_mutation                   object \n",
      " 1   date_mutation                 object \n",
      " 2   numero_disposition            Int64  \n",
      " 3   nature_mutation               object \n",
      " 4   valeur_fonciere               Float64\n",
      " 5   adresse_numero                Int64  \n",
      " 6   adresse_suffixe               string \n",
      " 7   adresse_nom_voie              object \n",
      " 8   adresse_code_voie             string \n",
      " 9   code_postal                   Int64  \n",
      " 10  code_commune                  string \n",
      " 11  code_departement              string \n",
      " 12  numero_volume                 string \n",
      " 13  lot1_numero                   string \n",
      " 14  lot1_surface_carrez           Float64\n",
      " 15  lot2_numero                   string \n",
      " 16  lot2_surface_carrez           Float64\n",
      " 17  lot3_numero                   string \n",
      " 18  lot3_surface_carrez           Float64\n",
      " 19  lot4_numero                   string \n",
      " 20  lot4_surface_carrez           Float64\n",
      " 21  lot5_numero                   string \n",
      " 22  lot5_surface_carrez           Float64\n",
      " 23  nombre_lots                   Int64  \n",
      " 24  code_type_local               Int64  \n",
      " 25  type_local                    string \n",
      " 26  surface_reelle_bati           float64\n",
      " 27  nombre_pieces_principales     Int64  \n",
      " 28  code_nature_culture           object \n",
      " 29  nature_culture                object \n",
      " 30  code_nature_culture_speciale  string \n",
      " 31  nature_culture_speciale       string \n",
      " 32  surface_terrain               float64\n",
      " 33  longitude                     Float64\n",
      " 34  latitude                      Float64\n",
      "dtypes: Float64(8), Int64(6), float64(2), object(6), string(13)\n",
      "memory usage: 815.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_appart.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d07d9db6-2907-4885-a434-56b270f0c34a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_appart.to_parquet('dvf_vente_appartement.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b220c-dfd4-4b61-ba8a-0e4aecd6c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('dvf_vente_maison_temp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908fd55-c8df-4452-accd-56136b8bf922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lot1_numero'][df['lot1_numero'].str.isnumeric()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817714b-c475-49eb-8756-244b6a35b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['adresse_code_voie'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795319d-2b05-4ac8-8651-9e504051c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881d12a-ae07-4b77-b82c-3f716bdd2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\n",
    "    'numero_disposition':'Int64',\n",
    "   'valeur_fonciere' : 'Float64',\n",
    "   'adresse_numero':'Int64','adresse_suffixe': 'string', 'code_postal': 'Int64','adresse_code_voie': 'string',\n",
    "   'code_commune': 'string', 'code_departement': 'string', \n",
    "  'numero_volume': 'string',\n",
    "   'lot1_numero': 'string','lot1_surface_carrez':'Float64',\n",
    "   'lot2_numero': 'string','lot2_surface_carrez':'Float64',\n",
    "   'lot3_numero': 'string','lot3_surface_carrez':'Float64',\n",
    "   'lot4_numero': 'string','lot4_surface_carrez':'Float64',\n",
    "   'lot5_numero': 'string','lot5_surface_carrez':'Float64',\n",
    "  'nombre_lots':'Int64','code_type_local':'Int64','type_local': 'string',\n",
    "  'surface_terrain':'float','surface_reelle_bati' : 'float','nombre_pieces_principales' : 'Int64',\n",
    "   'nature_culture_speciale': 'string','code_nature_culture_speciale': 'string',\n",
    "   'longitude':'Float64','latitude':'Float64'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4b8df-2d3a-4c0f-9801-f68f0c978107",
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_object = df.select_dtypes(include=['object']).columns\n",
    "for col in colonnes_object:\n",
    "    df[col] = df[col].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afec249-c303-4e82-893c-381c33eeafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['adresse_numero','adresse_numero']].apply(lambda x: x.astype('Int64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d329396a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a29de4-c14e-42ef-8002-431f814f1477",
   "metadata": {},
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ac30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dvf_to_parquet(fichier = './dvf.csv/dvf.csv'):\n",
    "    print(\"Conversion du fichier DVF en cours...\")\n",
    "    \n",
    "    # Charger par chunks pour éviter les erreurs mémoire\n",
    "    chunks = []\n",
    "    chunk_size = 50000\n",
    "    \n",
    "    for i, chunk in enumerate(pd.read_csv(fichier, sep=',', chunksize=chunk_size)):\n",
    "        print(f\"Traitement chunk {i+1}...\")\n",
    "        chunks.append(chunk)\n",
    "        \n",
    "        # Sauvegarder périodiquement pour éviter la surcharge mémoire\n",
    "        if len(chunks) == 10:  # Tous les 10 chunks\n",
    "            temp_df = pd.concat(chunks, ignore_index=True)\n",
    "            temp_df.to_parquet(f'dvf_temp_{str(i//10)}.parquet')\n",
    "            chunks = []\n",
    "    \n",
    "    # Traiter le dernier chunk\n",
    "    if chunks:\n",
    "        temp_df = pd.concat(chunks, ignore_index=True)\n",
    "        temp_df.to_parquet(f'dvf_temp_final.parquet')\n",
    "    \n",
    "    print(\"Conversion terminée!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598dffa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convert_dvf_to_parquet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d93465-38b8-4e79-ab0d-1eadb47c9fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db048c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM totale: 15.7 GB\n",
      "RAM disponible: 4.3 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "print(f\"RAM totale: {psutil.virtual_memory().total / (1024**3):.1f} GB\")\n",
    "print(f\"RAM disponible: {psutil.virtual_memory().available / (1024**3):.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384811fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir la taille du fichier\n",
    "import os\n",
    "taille_mb = os.path.getsize('./dvf.csv/dvf.csv') / (1024*1024)\n",
    "print(f\"Taille du fichier: {taille_mb:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f2bbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Charger le fichier par petits blocs\n",
    "chunk_size = 100000  # Ajustez selon votre RAM\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv('./dvf.csv/dvf.csv', sep=',', chunksize=chunk_size):\n",
    "    chunks.append(chunk)\n",
    "    \n",
    "# Combiner tous les chunks\n",
    "df = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a572e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./dvf.csv/dvf.csv', sep=',',nrows=100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3195852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805613ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.select_dtypes('object'):\n",
    "    print(f'les modalité de {i} sont : ',(df[i].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca0c68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Étape 1 : Lire tous les chunks et les stocker\n",
    "chunks = []  # Liste vide pour stocker les chunks\n",
    "\n",
    "chunk_size = 50000  # 50,000 lignes par chunk\n",
    "for chunk in pd.read_csv('./dvf.csv/dvf.csv', sep=',', chunksize=chunk_size):\n",
    "    chunks.append(chunk)  # Ajouter le chunk à la liste\n",
    "    print(f\"Chunk lu, {len(chunk)} lignes\")\n",
    "\n",
    "# Étape 2 : Recoller tous les chunks\n",
    "df_complet = pd.concat(chunks, ignore_index=True)\n",
    "print(f\"DataFrame final : {len(df_complet)} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37eb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7cd993d-3550-4285-a396-319a9612b695",
   "metadata": {},
   "source": [
    "## CSV to Parquet using \"dask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pip install dask\n",
    "pip install dask[dataframe]\n",
    "pip install dask[diagnostics]\n",
    "pip install polars\n",
    "'''\n",
    "from dask import dataframe as df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284890d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time taken to read data\n",
    "dask_df = df1.read_csv('./dvf.csv/dvf.csv', sep=',',\n",
    "                       dtype={ 'adresse_suffixe': 'object',\n",
    "                               'code_nature_culture_speciale': 'object',\n",
    "                               'code_postal': 'Int64',\n",
    "                               'lot1_numero': 'Int64',\n",
    "                               'lot2_numero': 'Int64',\n",
    "                               'lot3_numero': 'Int64',\n",
    "                               'nature_culture_speciale': 'object',\n",
    "                               'numero_volume': 'object',\n",
    "                               'surface_terrain': 'float64',\n",
    "                               'type_local': 'object',\n",
    "                               'valeur_fonciere': 'float64',\n",
    "                               'lot4_numero': 'object',\n",
    "                               'code_commune': 'object',\n",
    "                               'code_departement': 'object',\n",
    "                               'ancien_id_parcelle': 'object',\n",
    "                               'ancien_nom_commune': 'object',\n",
    "                               'lot5_numero': 'object',\n",
    "                               'adresse_code_voie': 'object'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919f7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_df.compute().to_parquet('mon_fichier.parquet', compression='snappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745640b7-03b0-4785-9383-b130ba4d8b99",
   "metadata": {},
   "source": [
    "## data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da760791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bf7e6-536f-44a9-a89a-2673830eaa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Read and sample with polars\n",
    "df = pl.read_parquet('./DVF.parquet')\n",
    "sample = df.sample(n=1000)\n",
    "# or\n",
    "sample = df.sample(fraction=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93814ee2-ccd5-4494-b61e-022fcec089e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=pd.DataFrame(sample,columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401fadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df=pd.read_parquet('./DVF.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0345a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.filter(like='lot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5571aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['numero_disposition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d6deb-3bd0-46b2-82ec-06bc148d1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['nature_mutation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9554d-1eea-4df0-b60a-e88c0da6deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['adresse_suffixe'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8e14d-6e22-43be-a511-4ead07c7d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['nature_mutation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d130e12-b247-4245-b24c-2f966489b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['adresse_numero'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f0b95-5aef-46b1-a70a-5eed82427780",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_sample['longitude'].astype('float')-df_sample['longitude'].astype('Float64')).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
